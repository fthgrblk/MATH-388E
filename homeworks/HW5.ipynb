{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW5\n",
    "\n",
    "For this homework, we are going to work with [*Indoor User Movement Prediction from RSS data*](https://archive.ics.uci.edu/ml/datasets/Indoor+User+Movement+Prediction+from+RSS+data) dataset from UCI.  The homework is due Friday, December 21st midnight. \n",
    "\n",
    "## Task 1\n",
    "\n",
    "Download the dataset and unzip it in under a subdirectory of `data` folder named `rss_data`.\n",
    "\n",
    "The files we are interested is in the subfolder `dataset`.  Each of these files whose names that start with `MovementAAL_RSS_` contain data collected from indivuduals. Each of these files represent a single data point.  There are 314 of these files, and hence, you have 314 data points.  Each file has 4 columns but the number of rows change from file to file.  \n",
    "\n",
    "There is also a file named `MovementALL_target.csv` in that folder. This file tells us the class each of these measurements are assigned. Some of these measurements are labelled with +1 and some are labelled with -1.\n",
    "\n",
    "## Task 2\n",
    "\n",
    "Construct a SVM model that separates +1 labelled data points from -1 data points.  You must first solve the problem that these datapoints do not have the same number of rows even though they all have the same number of columns. \n",
    "\n",
    "## Task 3\n",
    "\n",
    "Using [Keras](https://keras.io/getting-started/sequential-model-guide/) write a neural network model that separates +1 labelled data points from -1 data points.\n",
    "\n",
    "## Notes\n",
    "\n",
    "1. You must document each step of your tasks: what are you doing, why are you doing it, what problems you encountered and how you solved it.  All of these must be explained and documented.  Solutions without sufficient documentations will be penalized accordingly. 50% of your points will come from your code, while the other 50% will come from your explanations.\n",
    "\n",
    "1. You can use MS Excel to inspect the files, but loading them up to python using pandas and inspecting them there under jupyter is easier.\n",
    "\n",
    "3. Put the data in a separate subfolder of your `data` folder and rename it `rss_data`. I'll take points off if the data is not saved under the correct place.\n",
    "\n",
    "1. For both of Task 2 and Task 3, you must split your data into a train and test set, and then evaluate the accuracy of your model on the test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# TASK 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data yı hazırlıyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerekli kütüphaneler yüklendi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files=glob.glob(\"..//data//rss_data//dataset//MovementAAL_RSS_*.csv\")\n",
    "frames=[]\n",
    "for csv in csv_files:\n",
    "    df=pd.read_csv(csv)\n",
    "    frames.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "glob kütüphanesinin glob fonksiyonuyla 314 adet datayı csv_files listesine atadık for döngüsüyle de frames listesine attık"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "a=100\n",
    "for i in frames:\n",
    "    a=min(a,len(i))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datalar eşit değil en düşük olan sayıdakini bulup sondan kesicez son bulunduğu lokasyonu tespit için"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for i in frames:\n",
    "    for row in range(1,20):\n",
    "        for col in range(4):\n",
    "            l.append(i.iloc[-row,col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tüm datayı düz liste yapıp tekrar şekillendirip dataframe haline getiriyorum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=np.array(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=k.reshape(314,76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target datasını çekiyorum hangi odada fln olduğunu gösteren data ,(314,2) geldiği için sequence kolonunu atıyorum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.read_csv('..//data//rss_data//dataset//MovementAAL_target.csv')\n",
    "targets=targets.drop(\"#sequence_ID\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=np.column_stack([df,targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.14286</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.28571</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.047619</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-0.047619</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.095238</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.095238</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.142860</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.19048</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.38095</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.19048</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.190480</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.14286</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.142860</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.285710</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.28571</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-0.57143</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>0.33333</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-0.952380</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>0.14286</td>\n",
       "      <td>0.56</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>0.428570</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.619050</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.714290</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.28571</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-0.428570</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.380950</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.42857</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.28571</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>0.42857</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-0.476190</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.36</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.285710</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-0.571430</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.142860</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-0.666670</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1        2     3        4     5         6     7        8     9   \\\n",
       "0 -0.14286 -0.60 -0.28571 -0.10  0.00000  0.04 -0.047619 -0.05  0.00000  0.04   \n",
       "1  0.19048  0.04 -0.38095  0.20  0.19048  0.00 -0.190480 -0.25  0.14286 -0.04   \n",
       "2  0.28571  0.56 -0.57143 -0.75  0.33333  0.40 -0.952380 -0.65  0.14286  0.56   \n",
       "3  0.28571  0.20 -1.00000 -0.70  0.00000  0.04 -1.000000 -0.55  0.00000  0.04   \n",
       "4  0.42857  0.68 -0.28571 -0.30  0.42857  0.76 -0.476190 -0.60  0.00000  0.36   \n",
       "\n",
       "  ...     67        68    69        70    71        72    73        74    75  \\\n",
       "0 ...   0.40 -0.047619  0.04 -0.095238  0.05 -0.095238 -0.08  0.142860 -0.55   \n",
       "1 ...   0.10  0.000000 -0.12  0.142860  0.10 -0.285710 -0.24  0.095238  0.15   \n",
       "2 ...  -0.70  0.428570  0.04 -0.619050 -0.70  0.047619  0.32 -0.714290 -0.30   \n",
       "3 ...  -0.65  0.523810  0.60 -0.428570 -0.55  0.476190  0.32 -0.380950 -0.30   \n",
       "4 ...  -1.00  0.285710  0.60 -0.571430 -1.00  0.142860  0.76 -0.666670 -0.55   \n",
       "\n",
       "    76  \n",
       "0  1.0  \n",
       "1  1.0  \n",
       "2  1.0  \n",
       "3  1.0  \n",
       "4  1.0  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataframe haline getirilirdi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data hazırlandı."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Svm kütüphanelerini alma datayı bölme işlemleri aşağıda rfb en etkili olduğundan rfb yi seçtim gamma bir çok deneme sonrası optimal burda kaldı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7468354430379747\n",
      "[[29 11]\n",
      " [ 9 30]]\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(df.iloc[:,:76],df.iloc[:,76])\n",
    "sv=SVC(kernel=\"rbf\",gamma=0.03,C=2)\n",
    "sv.fit(X_train,y_train)\n",
    "predicted=sv.predict(X_test)\n",
    "print(accuracy_score(y_test,predicted))\n",
    "print(confusion_matrix(y_test,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data sonucu yeterli değil son zamanlarda machine learningin herkesin ağzında sakız olmasının sebebi olan neural network te daha başarılı olucak muhtemelen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras kütüphanelerini atma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer lstm_10: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-2f6212d13451>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m314\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecurrent_dropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m76\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m314\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecurrent_dropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m314\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecurrent_dropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    412\u001b[0m                 \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m                 \u001b[1;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m                 \u001b[1;31m# Collect input shapes to build layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m                                      str(K.ndim(x)))\n\u001b[0m\u001b[0;32m    312\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 is incompatible with layer lstm_10: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(76, 314))\n",
    "model.add(LSTM(314, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(32, activation='relu', input_dim=76))\n",
    "model.add(LSTM(314, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(LSTM(314, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(7, activation='sigmoid'))\n",
    "model.add(LSTM(314, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(LSTM(314, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "model.add(Dense(2, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please provide as model inputs either a single array or a list of arrays. You passed: x=           0         1         2         3         4         5         6   \\\n285  0.142860  0.440000 -0.857140 -0.450000  0.238100  0.040000 -0.714290   \n203 -0.545450 -0.777780  0.733330  0.276600 -0.545450 -0.600000  0.466670   \n169  0.000000  1.000000 -0.600000 -0.489360  0.136360  0.911110 -0.644440   \n99  -0.288890 -0.794870  0.681820  0.857140 -0.288890 -0.743590  0.772730   \n189 -0.380950 -0.040000  0.142860  0.050000 -0.428570  0.080000  0.142860   \n279  0.142860 -0.120000 -0.285710 -0.250000  0.000000 -0.040000 -0.285710   \n41  -0.333330 -0.538460 -0.818180 -0.904760 -0.333330  0.384620 -0.818180   \n33   1.000000  0.025641 -0.727270 -0.571430  1.000000 -0.025641 -0.590910   \n45   0.095238 -0.280000 -0.095238  0.250000  0.142860 -0.160000 -0.142860   \n284  0.571430  0.360000 -0.571430 -0.700000  0.714290  0.440000 -0.428570   \n193 -0.454550 -0.777780  0.288890  0.148940 -0.318180 -1.000000  0.333330   \n17   0.200000 -0.384620 -0.590910 -0.142860  0.200000 -0.384620 -0.590910   \n257 -0.428570  0.080000  0.285710 -0.400000 -0.428570  0.120000  0.142860   \n209 -0.318180 -0.777780  0.155560  0.361700 -0.318180 -0.688890  0.422220   \n221 -0.181820 -0.511110  0.066667 -0.063830 -0.181820 -0.333330  0.333330   \n223 -0.333330  0.040000 -0.142860  0.350000 -0.857140 -0.120000  0.000000   \n217 -0.727270 -0.822220  0.688890  0.574470 -0.727270 -0.644440  0.644440   \n139  0.000000  0.600000 -0.511110 -0.659570  0.000000  0.466670 -0.644440   \n298  0.761900  0.040000 -0.523810 -0.400000  0.571430  0.640000 -0.619050   \n178 -0.142860  0.040000  0.000000  0.100000 -0.238100  0.000000  0.000000   \n278  0.047619  0.040000 -0.190480 -0.250000  0.238100  0.040000 -0.380950   \n85   0.288890 -0.641030  0.363640  0.380950  0.288890 -0.538460  0.227270   \n172  0.363640 -0.288890 -0.955560 -0.489360  0.636360  0.333330 -0.688890   \n21   0.955560  0.333330 -1.000000 -1.000000  0.866670  0.538460 -0.727270   \n142  0.500000  0.155560 -0.822220 -0.914890  0.772730  0.066667 -0.644440   \n102 -0.200000 -0.538460  0.045455  0.428570 -0.200000 -0.641030  0.272730   \n243 -1.000000 -0.640000 -0.285710  0.350000 -0.904760 -0.600000  0.142860   \n15   0.466670  0.487180 -0.636360 -0.428570  0.600000  0.692310 -0.818180   \n280  0.571430  0.160000 -0.809520 -0.600000  0.714290  0.160000 -0.952380   \n293  0.000000 -0.440000 -0.857140 -0.450000  0.190480  0.200000 -0.523810   \n..        ...       ...       ...       ...       ...       ...       ...   \n1    0.190480  0.040000 -0.380950  0.200000  0.190480  0.000000 -0.190480   \n82  -0.244440 -0.743590  0.772730  0.190480 -0.200000 -0.384620  0.909090   \n47   0.111110  0.230770 -0.272730 -0.380950  0.066667  0.487180 -0.590910   \n271  0.285710  0.160000 -0.428570 -0.050000  0.380950  0.040000 -0.142860   \n147  0.181820 -0.022222 -0.600000 -0.617020  0.181820  0.377780 -1.000000   \n159  0.454550  0.244440 -0.777780 -0.531910  0.136360  0.466670 -0.600000   \n259 -0.523810 -0.440000  0.285710  0.800000 -0.571430 -0.600000  0.571430   \n256 -0.238100  0.160000  0.142860  0.300000 -0.285710  0.120000 -0.095238   \n260 -0.761900  0.040000  0.142860  0.350000 -0.714290  0.200000  0.142860   \n181 -0.454550 -0.466670  0.333330 -0.063830 -0.454550 -0.600000  0.733330   \n124 -0.155560 -0.384620  0.727270  1.000000 -0.422220 -0.794870  0.727270   \n283  0.142860  0.160000  0.095238 -0.100000  0.285710  0.080000  0.142860   \n152  0.909090  0.200000 -0.377780 -0.234040  0.909090 -0.333330 -0.777780   \n35   0.866670  0.333330 -0.590910 -0.380950  0.866670  0.384620 -0.954550   \n313  0.428570  0.600000 -1.000000 -0.600000  0.333330  0.200000 -0.857140   \n65  -0.200000 -0.846150  0.136360  0.142860 -0.200000 -1.000000 -0.045455   \n263  0.428570  0.160000 -0.142860 -0.400000  0.000000 -0.040000 -0.333330   \n237 -0.227270 -0.333330  0.377780 -0.574470 -0.227270 -0.244440  0.466670   \n183 -0.909090 -0.777780  0.200000 -0.191490 -0.909090 -1.000000  0.333330   \n130  0.727270 -0.111110 -0.511110 -0.489360  0.318180  0.155560 -0.600000   \n276 -0.142860  0.120000 -0.285710 -0.100000  0.333330  0.120000 -0.285710   \n158  0.500000 -0.066667 -1.000000 -0.617020  0.500000 -0.200000 -1.000000   \n176  0.363640  0.333330 -0.822220 -0.531910  0.363640  0.466670 -1.000000   \n128  0.863640 -0.688890 -0.955560 -0.531910  0.863640  0.244440 -0.955560   \n43   0.333330  0.538460 -0.772730 -0.428570  0.333330  0.230770 -0.727270   \n290 -0.428570  0.160000 -0.619050  0.050000  0.190480 -0.200000 -0.523810   \n116 -0.644440 -0.846150  0.500000  0.047619 -0.644440 -0.897440  0.318180   \n186 -0.454550 -0.511110  0.200000 -0.234040 -0.454550 -0.466670  0.200000   \n150 -0.181820 -0.466670 -0.777780 -0.446810  0.090909  0.022222 -0.200000   \n182 -0.681820 -1.000000  0.644440  0.148940 -0.681820 -0.777780  0.422220   \n\n          7         8         9     ...           66        67        68  \\\n285 -1.00000  0.571430  0.600000    ...    -0.904760 -0.700000  0.714290   \n203  0.14894 -0.545450 -0.555560    ...     0.066667  0.276600 -0.045455   \n169 -0.48936 -0.136360  0.866670    ...    -0.600000 -0.234040  0.227270   \n99   0.85714 -0.333330 -0.743590    ...     0.090909  0.285710 -0.200000   \n189  0.05000 -0.238100 -0.760000    ...     0.238100  0.100000 -0.619050   \n279 -0.30000  0.285710 -0.760000    ...    -0.904760 -1.000000  0.428570   \n41  -0.71429 -0.333330  0.230770    ...    -0.136360 -0.047619 -0.066667   \n33  -0.76190  1.000000  0.128210    ...    -0.818180 -0.523810  0.066667   \n45  -0.05000  0.142860 -0.120000    ...    -0.380950  0.250000 -0.142860   \n284 -0.65000  0.714290  0.680000    ...    -0.809520 -0.700000  0.571430   \n193  0.14894 -0.636360 -0.688890    ...     0.066667  0.148940 -0.954550   \n17  -0.14286  0.066667 -0.230770    ...    -0.181820 -0.142860  0.200000   \n257  0.30000 -0.857140  0.080000    ...     0.000000  0.200000 -0.619050   \n209  0.36170 -0.454550 -1.000000    ...     0.777780  0.574470 -0.363640   \n221 -0.06383 -0.090909 -0.600000    ...    -0.066667 -0.021277 -0.045455   \n223  0.55000 -0.333330 -0.320000    ...     0.000000 -0.200000 -0.952380   \n217  0.57447 -0.272730 -0.466670    ...     0.066667 -0.234040 -0.318180   \n139 -0.65957  0.227270  0.333330    ...    -0.822220 -0.489360  0.272730   \n298 -0.75000  0.857140  0.400000    ...    -0.571430 -1.000000  0.285710   \n178  0.00000 -0.428570 -0.520000    ...     0.285710  0.350000 -0.523810   \n278 -0.25000  0.047619  0.000000    ...    -0.714290 -0.850000  0.428570   \n85   0.57143  0.288890 -0.384620    ...     0.818180  0.285710 -0.955560   \n172 -0.48936  0.318180  0.111110    ...    -0.644440 -0.234040  0.136360   \n21  -1.00000  0.777780  0.692310    ...    -0.863640 -0.714290  0.377780   \n142 -0.91489  0.772730  0.066667    ...    -1.000000 -0.659570  0.000000   \n102  0.42857 -0.333330 -0.743590    ...     0.045455 -0.095238 -0.422220   \n243  0.20000 -0.904760 -0.520000    ...    -0.190480  0.750000 -0.571430   \n15  -0.42857  0.600000  0.384620    ...    -0.045455  0.000000  0.111110   \n280 -0.40000  0.714290  0.520000    ...    -0.809520 -0.500000  0.238100   \n293 -0.95000  0.238100  0.000000    ...    -0.666670 -0.550000  0.571430   \n..       ...       ...       ...    ...          ...       ...       ...   \n1   -0.25000  0.142860 -0.040000    ...    -0.190480  0.100000  0.000000   \n82   0.19048 -0.200000 -0.384620    ...     0.727270  0.809520 -0.066667   \n47  -0.38095  0.288890  0.487180    ...    -0.954550 -0.571430  0.422220   \n271 -0.15000  0.523810  0.240000    ...    -0.714290 -0.750000  0.190480   \n147 -0.53191  0.181820  0.377780    ...    -0.333330 -0.021277  0.090909   \n159 -0.53191  0.500000 -0.200000    ...    -0.511110 -0.234040  0.136360   \n259  0.90000 -0.904760 -0.600000    ...     0.190480  0.650000 -0.714290   \n256  0.35000 -0.285710 -0.080000    ...    -0.428570  0.150000 -0.714290   \n260 -0.15000 -0.952380  0.240000    ...    -0.142860 -0.400000 -0.619050   \n181 -0.06383 -0.409090 -0.733330    ...     0.066667  0.021277 -1.000000   \n124  1.00000 -0.555560 -1.000000    ...    -0.181820  0.571430 -0.422220   \n283  0.05000  0.285710  0.160000    ...    -0.523810 -0.450000  0.428570   \n152 -0.23404  0.818180  0.244440    ...    -1.000000 -0.659570  0.727270   \n35  -0.80952  0.866670  0.230770    ...    -1.000000 -0.523810  0.333330   \n313 -0.55000  0.285710  0.240000    ...    -0.523810 -1.000000  0.714290   \n65   0.14286 -0.555560 -1.000000    ...     0.318180  0.047619 -0.288890   \n263 -0.05000  0.523810 -0.200000    ...    -0.571430 -0.400000  0.380950   \n237 -0.57447 -0.227270 -0.200000    ...     0.377780  0.404260 -0.409090   \n183 -0.19149 -0.727270 -0.777780    ...     0.377780  0.021277 -0.863640   \n130 -0.48936  0.318180  0.333330    ...    -0.200000 -0.872340  0.227270   \n276 -0.10000  0.047619  0.040000    ...    -0.428570 -0.250000  0.428570   \n158 -0.61702  0.090909  0.200000    ...    -0.866670 -0.404260  0.227270   \n176 -0.36170  0.363640  0.600000    ...    -0.066667 -0.361700  0.227270   \n128 -0.53191  0.863640 -0.466670    ...    -0.733330 -0.659570  0.136360   \n43  -0.42857  0.333330  0.538460    ...    -0.181820  0.190480  0.066667   \n290 -0.25000 -0.428570  0.040000    ...    -0.285710 -0.500000  0.047619   \n116  0.85714 -0.733330 -0.538460    ...     0.000000  0.714290 -0.333330   \n186 -0.23404 -0.545450 -0.466670    ...     0.466670 -0.021277 -0.954550   \n150 -0.44681  0.181820 -0.022222    ...    -0.066667 -0.063830 -0.090909   \n182 -0.53191 -0.681820 -0.600000    ...     0.555560  0.404260 -0.454550   \n\n           69        70        71        72        73        74        75  \n285  0.680000 -0.619050 -0.600000  0.761900  0.720000 -0.523810 -0.650000  \n203 -0.511110 -0.600000 -0.106380 -0.045455 -0.200000 -0.244440 -0.063830  \n169  0.200000 -0.733330 -0.234040  0.500000  0.466670 -0.733330 -0.361700  \n99  -0.384620  0.227270  0.285710 -0.200000 -0.384620 -0.090909  0.333330  \n189 -0.080000 -0.047619  0.600000 -0.523810 -0.200000  0.047619  0.500000  \n279 -0.160000 -0.523810 -1.000000  0.380950  0.760000 -0.714290 -1.000000  \n41  -0.384620 -0.318180  0.238100 -0.066667 -0.076923 -0.181820  0.285710  \n33   0.641030 -0.954550 -0.571430  0.466670  0.846150 -0.954550 -0.571430  \n45  -0.200000 -0.142860  0.050000 -0.380950 -0.240000  0.095238  0.050000  \n284  0.640000 -0.571430 -1.000000  0.571430  0.640000 -0.904760 -0.800000  \n193 -1.000000  0.466670  0.148940 -0.454550 -0.955560  0.466670  0.148940  \n17   0.025641 -0.318180 -0.142860  0.200000  0.076923 -0.363640 -0.142860  \n257 -0.120000  0.000000  0.350000 -0.761900 -0.080000  0.000000 -0.550000  \n209 -0.955560  0.644440  0.574470 -0.318180 -0.688890  0.733330  0.574470  \n221 -0.600000  0.066667 -0.021277 -0.045455 -0.200000  0.111110  0.148940  \n223 -0.440000  0.142860 -0.250000 -0.619050 -0.200000  0.000000  0.350000  \n217 -0.466670  0.066667 -0.106380 -0.045455 -0.466670  0.066667 -0.021277  \n139 -0.377780 -0.866670 -0.489360  0.227270 -0.466670 -0.733330 -0.829790  \n298  0.640000 -0.428570 -1.000000  0.333330  0.760000 -1.000000 -0.650000  \n178 -0.240000 -0.142860  0.650000 -0.857140 -0.360000  0.190480  0.550000  \n278  0.640000 -0.714290 -0.550000  0.761900  0.640000 -0.619050 -0.650000  \n85  -0.743590  0.772730  0.571430 -0.377780 -0.692310  0.818180  0.571430  \n172  0.200000 -0.733330 -0.234040 -0.136360  0.200000 -0.466670 -0.361700  \n21   0.538460 -1.000000 -0.904760  0.377780 -0.128210 -1.000000 -1.000000  \n142 -0.466670 -0.733330 -0.659570  0.227270  0.422220 -0.955560 -0.702130  \n102 -1.000000 -0.045455 -0.095238  0.155560 -0.384620 -0.136360 -0.095238  \n243 -0.640000  0.095238  0.650000 -1.000000 -0.400000  0.047619 -0.050000  \n15  -0.641030  0.090909  0.000000  0.111110  0.076923 -0.136360  0.142860  \n280  0.760000 -0.571430 -1.000000  0.380950  0.720000 -0.904760 -0.700000  \n293  0.040000 -0.571430 -0.800000  0.666670  0.040000 -0.428570 -0.550000  \n..        ...       ...       ...       ...       ...       ...       ...  \n1   -0.120000  0.142860  0.100000 -0.285710 -0.240000  0.095238  0.150000  \n82  -0.538460  0.772730  0.809520 -0.066667 -0.384620  0.727270  0.285710  \n47   0.538460 -0.772730 -0.571430  0.422220  0.538460 -1.000000 -0.523810  \n271  0.880000 -0.714290 -1.000000  0.190480  0.880000 -0.904760 -1.000000  \n147  0.022222 -0.333330  0.191490  0.090909 -0.022222 -0.244440 -0.106380  \n159 -0.422220 -1.000000 -0.234040 -0.045455 -0.200000  0.022222 -0.914890  \n259 -0.480000  0.428570  0.350000 -1.000000 -0.440000  0.571430  0.350000  \n256 -0.040000  0.142860  0.200000 -0.476190 -0.080000 -0.095238 -0.100000  \n260 -0.760000 -0.095238 -0.150000 -0.952380 -0.760000  0.000000 -0.550000  \n181 -0.688890  0.288890  0.276600 -1.000000 -0.866670  0.422220  0.276600  \n124 -0.692310  0.363640  0.571430 -0.422220 -0.538460  0.363640  0.714290  \n283  0.120000 -0.571430 -0.700000  0.142860  0.160000 -0.571430 -0.650000  \n152 -0.200000 -0.911110 -0.361700  0.727270 -0.200000 -0.822220 -0.361700  \n35   0.589740 -1.000000 -0.523810  0.333330  0.025641 -1.000000 -1.000000  \n313  0.160000 -1.000000 -1.000000  0.571430  0.200000 -0.476190 -0.650000  \n65  -0.692310  0.227270  0.333330 -0.066667 -0.794870  0.363640  0.333330  \n263  0.040000 -0.571430 -0.250000  0.571430 -0.200000 -0.904760 -0.400000  \n237 -0.466670  0.288890  0.404260 -0.772730 -0.466670  0.200000  0.404260  \n183 -0.466670  0.466670  0.021277  0.045455 -0.600000  0.600000  0.021277  \n130 -0.644440 -0.200000 -0.872340  0.227270 -0.066667 -0.422220 -0.872340  \n276  0.200000 -0.476190 -0.150000  0.428570  0.280000 -0.428570 -0.200000  \n158  0.111110 -0.244440 -0.148940  0.227270  0.200000 -0.377780 -0.489360  \n176  0.066667 -0.066667 -0.361700  0.227270 -0.333330 -0.200000 -0.361700  \n128  0.333330 -0.511110 -0.659570  0.136360  0.333330 -0.822220 -0.659570  \n43  -0.384620 -0.272730  0.190480  0.066667 -0.076923 -0.090909  0.190480  \n290  0.080000 -0.285710 -1.000000  0.428570  0.040000 -0.285710 -1.000000  \n116 -0.230770  0.090909  0.571430 -0.333330 -0.487180  0.090909  0.476190  \n186 -0.733330  0.600000  0.021277 -0.954550 -0.777780  0.066667 -0.319150  \n150  0.111110 -0.333330 -0.234040 -0.090909  0.111110 -0.200000  0.148940  \n182 -0.511110  0.466670  0.404260 -0.590910 -0.955560  0.466670 -0.234040  \n\n[235 rows x 76 columns]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-bbda8d5644c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    668\u001b[0m                                      \u001b[1;34m'either a single '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m                                      \u001b[1;34m'array or a list of arrays. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m                                      'You passed: x=' + str(x))\n\u001b[0m\u001b[0;32m    671\u001b[0m                 \u001b[0mall_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Please provide as model inputs either a single array or a list of arrays. You passed: x=           0         1         2         3         4         5         6   \\\n285  0.142860  0.440000 -0.857140 -0.450000  0.238100  0.040000 -0.714290   \n203 -0.545450 -0.777780  0.733330  0.276600 -0.545450 -0.600000  0.466670   \n169  0.000000  1.000000 -0.600000 -0.489360  0.136360  0.911110 -0.644440   \n99  -0.288890 -0.794870  0.681820  0.857140 -0.288890 -0.743590  0.772730   \n189 -0.380950 -0.040000  0.142860  0.050000 -0.428570  0.080000  0.142860   \n279  0.142860 -0.120000 -0.285710 -0.250000  0.000000 -0.040000 -0.285710   \n41  -0.333330 -0.538460 -0.818180 -0.904760 -0.333330  0.384620 -0.818180   \n33   1.000000  0.025641 -0.727270 -0.571430  1.000000 -0.025641 -0.590910   \n45   0.095238 -0.280000 -0.095238  0.250000  0.142860 -0.160000 -0.142860   \n284  0.571430  0.360000 -0.571430 -0.700000  0.714290  0.440000 -0.428570   \n193 -0.454550 -0.777780  0.288890  0.148940 -0.318180 -1.000000  0.333330   \n17   0.200000 -0.384620 -0.590910 -0.142860  0.200000 -0.384620 -0.590910   \n257 -0.428570  0.080000  0.285710 -0.400000 -0.428570  0.120000  0.142860   \n209 -0.318180 -0.777780  0.155560  0.361700 -0.318180 -0.688890  0.422220   \n221 -0.181820 -0.511110  0.066667 -0.063830 -0.181820 -0.333330  0.333330   \n223 -0.333330  0.040000 -0.142860  0.350000 -0.857140 -0.120000  0.000000   \n217 -0.727270 -0.822220  0.688890  0.574470 -0.727270 -0.644440  0.644440   \n139  0.000000  0.600000 -0.511110 -0.659570  0.000000  0.466670 -0.644440   \n298  0.761900  0.040000 -0.523810 -0.400000  0.571430  0.640000 -0.619050   \n178 -0.142860  0.040000  0.000000  0.100000 -0.238100  0.000000  0.000000   \n278  0.047619  0.040000 -0.190480 -0.250000  0.238100  0.040000 -0.380950   \n85   0.288890 -0.641030  0.363640  0.380950  0.288890 -0.538460  0.227270   \n172  0.363640 -0.288890 -0.955560 -0.489360  0.636360  0.333330 -0.688890   \n21   0.955560  0.333330 -1.000000 -1.000000  0.866670  0.538460 -0.727270   \n142  0.500000  0.155560 -0.822220 -0.914890  0.772730  0.066667 -0.644440   \n102 -0.200000 -0.538460  0.045455  0.428570 -0.200000 -0.641030  0.272730   \n243 -1.000000 -0.640000 -0.285710  0.350000 -0.904760 -0.600000  0.142860   \n15   0.466670  0.487180 -0.636360 -0.428570  0.600000  0.692310 -0.818180   \n280  0.571430  0.160000 -0.809520 -0.600000  0.714290  0.160000 -0.952380   \n293  0.000000 -0.440000 -0.857140 -0.450000  0.190480  0.200000 -0.523810   \n..        ...       ...       ...       ...       ...       ...       ...   \n1    0.190480  0.040000 -0.380950  0.200000  0.190480  0.000000 -0.190480   \n82  -0.244440 -0.743590  0.772730  0.190480 -0.200000 -0.384620  0.909090   \n47   0.111110  0.230770 -0.272730 -0.380950  0.066667  0.487180 -0.590910   \n271  0.285710  0.160000 -0.428570 -0.050000  0.380950  0.040000 -0.142860   \n147  0.181820 -0.022222 -0.600000 -0.617020  0.181820  0.377780 -1.000000   \n159  0.454550  0.244440 -0.777780 -0.531910  0.136360  0.466670 -0.600000   \n259 -0.523810 -0.440000  0.285710  0.800000 -0.571430 -0.600000  0.571430   \n256 -0.238100  0.160000  0.142860  0.300000 -0.285710  0.120000 -0.095238   \n260 -0.761900  0.040000  0.142860  0.350000 -0.714290  0.200000  0.142860   \n181 -0.454550 -0.466670  0.333330 -0.063830 -0.454550 -0.600000  0.733330   \n124 -0.155560 -0.384620  0.727270  1.000000 -0.422220 -0.794870  0.727270   \n283  0.142860  0.160000  0.095238 -0.100000  0.285710  0.080000  0.142860   \n152  0.909090  0.200000 -0.377780 -0.234040  0.909090 -0.333330 -0.777780   \n35   0.866670  0.333330 -0.590910 -0.380950  0.866670  0.384620 -0.954550   \n313  0.428570  0.600000 -1.000000 -0.600000  0.333330  0.200000 -0.857140   \n65  -0.200000 -0.846150  0.136360  0.142860 -0.200000 -1.000000 -0.045455   \n263  0.428570  0.160000 -0.142860 -0.400000  0.000000 -0.040000 -0.333330   \n237 -0.227270 -0.333330  0.377780 -0.574470 -0.227270 -0.244440  0.466670   \n183 -0.909090 -0.777780  0.200000 -0.191490 -0.909090 -1.000000  0.333330   \n130  0.727270 -0.111110 -0.511110 -0.489360  0.318180  0.155560 -0.600000   \n276 -0.142860  0.120000 -0.285710 -0.100000  0.333330  0.120000 -0.285710   \n158  0.500000 -0.066667 -1.000000 -0.617020  0.500000 -0.200000 -1.000000   \n176  0.363640  0.333330 -0.822220 -0.531910  0.363640  0.466670 -1.000000   \n128  0.863640 -0.688890 -0.955560 -0.531910  0.863640  0.244440 -0.955560   \n43   0.333330  0.538460 -0.772730 -0.428570  0.333330  0.230770 -0.727270   \n290 -0.428570  0.160000 -0.619050  0.050000  0.190480 -0.200000 -0.523810   \n116 -0.644440 -0.846150  0.500000  0.047619 -0.644440 -0.897440  0.318180   \n186 -0.454550 -0.511110  0.200000 -0.234040 -0.454550 -0.466670  0.200000   \n150 -0.181820 -0.466670 -0.777780 -0.446810  0.090909  0.022222 -0.200000   \n182 -0.681820 -1.000000  0.644440  0.148940 -0.681820 -0.777780  0.422220   \n\n          7         8         9     ...           66        67        68  \\\n285 -1.00000  0.571430  0.600000    ...    -0.904760 -0.700000  0.714290   \n203  0.14894 -0.545450 -0.555560    ...     0.066667  0.276600 -0.045455   \n169 -0.48936 -0.136360  0.866670    ...    -0.600000 -0.234040  0.227270   \n99   0.85714 -0.333330 -0.743590    ...     0.090909  0.285710 -0.200000   \n189  0.05000 -0.238100 -0.760000    ...     0.238100  0.100000 -0.619050   \n279 -0.30000  0.285710 -0.760000    ...    -0.904760 -1.000000  0.428570   \n41  -0.71429 -0.333330  0.230770    ...    -0.136360 -0.047619 -0.066667   \n33  -0.76190  1.000000  0.128210    ...    -0.818180 -0.523810  0.066667   \n45  -0.05000  0.142860 -0.120000    ...    -0.380950  0.250000 -0.142860   \n284 -0.65000  0.714290  0.680000    ...    -0.809520 -0.700000  0.571430   \n193  0.14894 -0.636360 -0.688890    ...     0.066667  0.148940 -0.954550   \n17  -0.14286  0.066667 -0.230770    ...    -0.181820 -0.142860  0.200000   \n257  0.30000 -0.857140  0.080000    ...     0.000000  0.200000 -0.619050   \n209  0.36170 -0.454550 -1.000000    ...     0.777780  0.574470 -0.363640   \n221 -0.06383 -0.090909 -0.600000    ...    -0.066667 -0.021277 -0.045455   \n223  0.55000 -0.333330 -0.320000    ...     0.000000 -0.200000 -0.952380   \n217  0.57447 -0.272730 -0.466670    ...     0.066667 -0.234040 -0.318180   \n139 -0.65957  0.227270  0.333330    ...    -0.822220 -0.489360  0.272730   \n298 -0.75000  0.857140  0.400000    ...    -0.571430 -1.000000  0.285710   \n178  0.00000 -0.428570 -0.520000    ...     0.285710  0.350000 -0.523810   \n278 -0.25000  0.047619  0.000000    ...    -0.714290 -0.850000  0.428570   \n85   0.57143  0.288890 -0.384620    ...     0.818180  0.285710 -0.955560   \n172 -0.48936  0.318180  0.111110    ...    -0.644440 -0.234040  0.136360   \n21  -1.00000  0.777780  0.692310    ...    -0.863640 -0.714290  0.377780   \n142 -0.91489  0.772730  0.066667    ...    -1.000000 -0.659570  0.000000   \n102  0.42857 -0.333330 -0.743590    ...     0.045455 -0.095238 -0.422220   \n243  0.20000 -0.904760 -0.520000    ...    -0.190480  0.750000 -0.571430   \n15  -0.42857  0.600000  0.384620    ...    -0.045455  0.000000  0.111110   \n280 -0.40000  0.714290  0.520000    ...    -0.809520 -0.500000  0.238100   \n293 -0.95000  0.238100  0.000000    ...    -0.666670 -0.550000  0.571430   \n..       ...       ...       ...    ...          ...       ...       ...   \n1   -0.25000  0.142860 -0.040000    ...    -0.190480  0.100000  0.000000   \n82   0.19048 -0.200000 -0.384620    ...     0.727270  0.809520 -0.066667   \n47  -0.38095  0.288890  0.487180    ...    -0.954550 -0.571430  0.422220   \n271 -0.15000  0.523810  0.240000    ...    -0.714290 -0.750000  0.190480   \n147 -0.53191  0.181820  0.377780    ...    -0.333330 -0.021277  0.090909   \n159 -0.53191  0.500000 -0.200000    ...    -0.511110 -0.234040  0.136360   \n259  0.90000 -0.904760 -0.600000    ...     0.190480  0.650000 -0.714290   \n256  0.35000 -0.285710 -0.080000    ...    -0.428570  0.150000 -0.714290   \n260 -0.15000 -0.952380  0.240000    ...    -0.142860 -0.400000 -0.619050   \n181 -0.06383 -0.409090 -0.733330    ...     0.066667  0.021277 -1.000000   \n124  1.00000 -0.555560 -1.000000    ...    -0.181820  0.571430 -0.422220   \n283  0.05000  0.285710  0.160000    ...    -0.523810 -0.450000  0.428570   \n152 -0.23404  0.818180  0.244440    ...    -1.000000 -0.659570  0.727270   \n35  -0.80952  0.866670  0.230770    ...    -1.000000 -0.523810  0.333330   \n313 -0.55000  0.285710  0.240000    ...    -0.523810 -1.000000  0.714290   \n65   0.14286 -0.555560 -1.000000    ...     0.318180  0.047619 -0.288890   \n263 -0.05000  0.523810 -0.200000    ...    -0.571430 -0.400000  0.380950   \n237 -0.57447 -0.227270 -0.200000    ...     0.377780  0.404260 -0.409090   \n183 -0.19149 -0.727270 -0.777780    ...     0.377780  0.021277 -0.863640   \n130 -0.48936  0.318180  0.333330    ...    -0.200000 -0.872340  0.227270   \n276 -0.10000  0.047619  0.040000    ...    -0.428570 -0.250000  0.428570   \n158 -0.61702  0.090909  0.200000    ...    -0.866670 -0.404260  0.227270   \n176 -0.36170  0.363640  0.600000    ...    -0.066667 -0.361700  0.227270   \n128 -0.53191  0.863640 -0.466670    ...    -0.733330 -0.659570  0.136360   \n43  -0.42857  0.333330  0.538460    ...    -0.181820  0.190480  0.066667   \n290 -0.25000 -0.428570  0.040000    ...    -0.285710 -0.500000  0.047619   \n116  0.85714 -0.733330 -0.538460    ...     0.000000  0.714290 -0.333330   \n186 -0.23404 -0.545450 -0.466670    ...     0.466670 -0.021277 -0.954550   \n150 -0.44681  0.181820 -0.022222    ...    -0.066667 -0.063830 -0.090909   \n182 -0.53191 -0.681820 -0.600000    ...     0.555560  0.404260 -0.454550   \n\n           69        70        71        72        73        74        75  \n285  0.680000 -0.619050 -0.600000  0.761900  0.720000 -0.523810 -0.650000  \n203 -0.511110 -0.600000 -0.106380 -0.045455 -0.200000 -0.244440 -0.063830  \n169  0.200000 -0.733330 -0.234040  0.500000  0.466670 -0.733330 -0.361700  \n99  -0.384620  0.227270  0.285710 -0.200000 -0.384620 -0.090909  0.333330  \n189 -0.080000 -0.047619  0.600000 -0.523810 -0.200000  0.047619  0.500000  \n279 -0.160000 -0.523810 -1.000000  0.380950  0.760000 -0.714290 -1.000000  \n41  -0.384620 -0.318180  0.238100 -0.066667 -0.076923 -0.181820  0.285710  \n33   0.641030 -0.954550 -0.571430  0.466670  0.846150 -0.954550 -0.571430  \n45  -0.200000 -0.142860  0.050000 -0.380950 -0.240000  0.095238  0.050000  \n284  0.640000 -0.571430 -1.000000  0.571430  0.640000 -0.904760 -0.800000  \n193 -1.000000  0.466670  0.148940 -0.454550 -0.955560  0.466670  0.148940  \n17   0.025641 -0.318180 -0.142860  0.200000  0.076923 -0.363640 -0.142860  \n257 -0.120000  0.000000  0.350000 -0.761900 -0.080000  0.000000 -0.550000  \n209 -0.955560  0.644440  0.574470 -0.318180 -0.688890  0.733330  0.574470  \n221 -0.600000  0.066667 -0.021277 -0.045455 -0.200000  0.111110  0.148940  \n223 -0.440000  0.142860 -0.250000 -0.619050 -0.200000  0.000000  0.350000  \n217 -0.466670  0.066667 -0.106380 -0.045455 -0.466670  0.066667 -0.021277  \n139 -0.377780 -0.866670 -0.489360  0.227270 -0.466670 -0.733330 -0.829790  \n298  0.640000 -0.428570 -1.000000  0.333330  0.760000 -1.000000 -0.650000  \n178 -0.240000 -0.142860  0.650000 -0.857140 -0.360000  0.190480  0.550000  \n278  0.640000 -0.714290 -0.550000  0.761900  0.640000 -0.619050 -0.650000  \n85  -0.743590  0.772730  0.571430 -0.377780 -0.692310  0.818180  0.571430  \n172  0.200000 -0.733330 -0.234040 -0.136360  0.200000 -0.466670 -0.361700  \n21   0.538460 -1.000000 -0.904760  0.377780 -0.128210 -1.000000 -1.000000  \n142 -0.466670 -0.733330 -0.659570  0.227270  0.422220 -0.955560 -0.702130  \n102 -1.000000 -0.045455 -0.095238  0.155560 -0.384620 -0.136360 -0.095238  \n243 -0.640000  0.095238  0.650000 -1.000000 -0.400000  0.047619 -0.050000  \n15  -0.641030  0.090909  0.000000  0.111110  0.076923 -0.136360  0.142860  \n280  0.760000 -0.571430 -1.000000  0.380950  0.720000 -0.904760 -0.700000  \n293  0.040000 -0.571430 -0.800000  0.666670  0.040000 -0.428570 -0.550000  \n..        ...       ...       ...       ...       ...       ...       ...  \n1   -0.120000  0.142860  0.100000 -0.285710 -0.240000  0.095238  0.150000  \n82  -0.538460  0.772730  0.809520 -0.066667 -0.384620  0.727270  0.285710  \n47   0.538460 -0.772730 -0.571430  0.422220  0.538460 -1.000000 -0.523810  \n271  0.880000 -0.714290 -1.000000  0.190480  0.880000 -0.904760 -1.000000  \n147  0.022222 -0.333330  0.191490  0.090909 -0.022222 -0.244440 -0.106380  \n159 -0.422220 -1.000000 -0.234040 -0.045455 -0.200000  0.022222 -0.914890  \n259 -0.480000  0.428570  0.350000 -1.000000 -0.440000  0.571430  0.350000  \n256 -0.040000  0.142860  0.200000 -0.476190 -0.080000 -0.095238 -0.100000  \n260 -0.760000 -0.095238 -0.150000 -0.952380 -0.760000  0.000000 -0.550000  \n181 -0.688890  0.288890  0.276600 -1.000000 -0.866670  0.422220  0.276600  \n124 -0.692310  0.363640  0.571430 -0.422220 -0.538460  0.363640  0.714290  \n283  0.120000 -0.571430 -0.700000  0.142860  0.160000 -0.571430 -0.650000  \n152 -0.200000 -0.911110 -0.361700  0.727270 -0.200000 -0.822220 -0.361700  \n35   0.589740 -1.000000 -0.523810  0.333330  0.025641 -1.000000 -1.000000  \n313  0.160000 -1.000000 -1.000000  0.571430  0.200000 -0.476190 -0.650000  \n65  -0.692310  0.227270  0.333330 -0.066667 -0.794870  0.363640  0.333330  \n263  0.040000 -0.571430 -0.250000  0.571430 -0.200000 -0.904760 -0.400000  \n237 -0.466670  0.288890  0.404260 -0.772730 -0.466670  0.200000  0.404260  \n183 -0.466670  0.466670  0.021277  0.045455 -0.600000  0.600000  0.021277  \n130 -0.644440 -0.200000 -0.872340  0.227270 -0.066667 -0.422220 -0.872340  \n276  0.200000 -0.476190 -0.150000  0.428570  0.280000 -0.428570 -0.200000  \n158  0.111110 -0.244440 -0.148940  0.227270  0.200000 -0.377780 -0.489360  \n176  0.066667 -0.066667 -0.361700  0.227270 -0.333330 -0.200000 -0.361700  \n128  0.333330 -0.511110 -0.659570  0.136360  0.333330 -0.822220 -0.659570  \n43  -0.384620 -0.272730  0.190480  0.066667 -0.076923 -0.090909  0.190480  \n290  0.080000 -0.285710 -1.000000  0.428570  0.040000 -0.285710 -1.000000  \n116 -0.230770  0.090909  0.571430 -0.333330 -0.487180  0.090909  0.476190  \n186 -0.733330  0.600000  0.021277 -0.954550 -0.777780  0.066667 -0.319150  \n150  0.111110 -0.333330 -0.234040 -0.090909  0.111110 -0.200000  0.148940  \n182 -0.511110  0.466670  0.404260 -0.590910 -0.955560  0.466670 -0.234040  \n\n[235 rows x 76 columns]"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[2,33] = -1 is not in [0, 76)\n\t [[Node: embedding_5/embedding_lookup = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@embedding_5/embeddings\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_5/embeddings/read, embedding_5/Cast)]]\n\nCaused by op 'embedding_5/embedding_lookup', defined at:\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\asyncio\\base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-51-182f15caf0c9>\", line 7, in <module>\n    model.add(Embedding(76, output_dim=76))\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\", line 165, in add\n    layer(x)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 457, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\keras\\layers\\embeddings.py\", line 141, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 1228, in gather\n    return tf.nn.embedding_lookup(reference, indices)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\embedding_ops.py\", line 325, in embedding_lookup\n    transform_fn=None)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\embedding_ops.py\", line 150, in _embedding_lookup_and_transform\n    result = _clip(_gather(params[0], ids, name=name), ids, max_norm)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\embedding_ops.py\", line 54, in _gather\n    return array_ops.gather(params, ids, name=name)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 2585, in gather\n    params, indices, validate_indices=validate_indices, name=name)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 2334, in gather\n    validate_indices=validate_indices, name=name)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): indices[2,33] = -1 is not in [0, 76)\n\t [[Node: embedding_5/embedding_lookup = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@embedding_5/embeddings\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_5/embeddings/read, embedding_5/Cast)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: indices[2,33] = -1 is not in [0, 76)\n\t [[Node: embedding_5/embedding_lookup = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@embedding_5/embeddings\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_5/embeddings/read, embedding_5/Cast)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-182f15caf0c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2719\u001b[0m                     \u001b[1;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[1;32m-> 2721\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2693\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2694\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1363\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1365\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: indices[2,33] = -1 is not in [0, 76)\n\t [[Node: embedding_5/embedding_lookup = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@embedding_5/embeddings\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_5/embeddings/read, embedding_5/Cast)]]\n\nCaused by op 'embedding_5/embedding_lookup', defined at:\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\asyncio\\base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-51-182f15caf0c9>\", line 7, in <module>\n    model.add(Embedding(76, output_dim=76))\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\", line 165, in add\n    layer(x)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 457, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\keras\\layers\\embeddings.py\", line 141, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 1228, in gather\n    return tf.nn.embedding_lookup(reference, indices)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\embedding_ops.py\", line 325, in embedding_lookup\n    transform_fn=None)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\embedding_ops.py\", line 150, in _embedding_lookup_and_transform\n    result = _clip(_gather(params[0], ids, name=name), ids, max_norm)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\embedding_ops.py\", line 54, in _gather\n    return array_ops.gather(params, ids, name=name)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 2585, in gather\n    params, indices, validate_indices=validate_indices, name=name)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 2334, in gather\n    validate_indices=validate_indices, name=name)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\gurbu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): indices[2,33] = -1 is not in [0, 76)\n\t [[Node: embedding_5/embedding_lookup = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@embedding_5/embeddings\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_5/embeddings/read, embedding_5/Cast)]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(76, output_dim=76))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=16, epochs=10)\n",
    "score = model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
